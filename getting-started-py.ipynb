{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (PART) GETTING STARTED {-}\n",
    "\n",
    "#  Setting Up Your Development Environment {#setup-dev-envt}\n",
    "\n",
    "Before diving into the Q&A sections, it's important to ensure your environment is properly set up. This section will guide you through the steps to prepare everything you need to start working with both Python and R. To begin working with data science, youâ€™ll need to set up your development environment. Follow the steps below to install and configure the necessary tools.\n",
    "\n",
    "\n",
    "```{r, echo=FALSE, include=FALSE}\n",
    "knitr::opts_chunk$set(\n",
    "  echo  =TRUE,\n",
    "  message  =FALSE,\n",
    "  warning  =FALSE,\n",
    "  cache  =FALSE,\n",
    "  comment  =NA\n",
    ")\n",
    "\n",
    "if(!require(\"tidyverse\")) {\n",
    "  install.packages(\"tidyverse\")\n",
    "  library(tidyverse)}\n",
    "```\n",
    "\n",
    "## Install Python\n",
    "\n",
    "1. Visit the official [Python website](https://www.python.org/downloads/) to download and install the latest version of Python.\n",
    "2. During installation, ensure that you check the box to **add Python to your PATH**.\n",
    "\n",
    "## Install R\n",
    "\n",
    "1. Visit the official [R Project website](https://cran.r-project.org/) to download and install the latest version of R.\n",
    "2. Follow the installation instructions for your operating system.\n",
    "\n",
    "## Install VSCode\n",
    "\n",
    "### Why Use VSCode?\n",
    "**Visual Studio Code (VSCode)** is a lightweight, free, and powerful code editor that supports multiple programming languages, including **Python** and **R**. It provides an interactive environment for writing, running, and debugging code efficiently.  \n",
    "\n",
    "### Installation Steps:\n",
    "1. Download and install **Visual Studio Code (VSCode)** from the [official VSCode website](https://code.visualstudio.com/).\n",
    "2. Once installed, open VSCode and install the necessary extensions to enable support for Python and R.\n",
    "\n",
    "### **Installing Extensions in VSCode**\n",
    "Extensions enhance the functionality of VSCode by adding language support, debugging tools, and other useful features.\n",
    "\n",
    "**For Python:**\n",
    "\n",
    "- Open VSCode.\n",
    "- Press `Ctrl + Shift + X` (Windows/Linux) or `Cmd + Shift + X` (Mac) to open the Extensions Marketplace.\n",
    "- Search for **Python** (developed by Microsoft).\n",
    "- Click **Install**.\n",
    "- This extension provides:\n",
    "  - **IntelliSense** (code completion, function suggestions, and real-time error checking).\n",
    "  - Debugging support.\n",
    "  - Jupyter Notebook integration.\n",
    "  - Formatting and linting tools.\n",
    "\n",
    "**For R:**\n",
    "\n",
    "- In the Extensions Marketplace, search for **R**.\n",
    "- Click **Install**.\n",
    "- This extension provides:\n",
    "  - **IntelliSense** for R functions and datasets.\n",
    "  - Integrated R terminal for running scripts.\n",
    "  - Debugging support.\n",
    "\n",
    "**What is IntelliSense?**\n",
    "\n",
    "**IntelliSense** is an advanced code assistance feature that helps you write code faster and with fewer errors by providing **autocomplete suggestions, function hints, and real-time error checking**. It makes coding in Python and R easier by suggesting function names, displaying expected arguments, and highlighting errors before you run the code.\n",
    "\n",
    "**Verify Installation**\n",
    "\n",
    "After installing VSCode and the extensions:\n",
    "\n",
    "- Open VSCode and check if the extensions are enabled.\n",
    "- Open a Python or R script to ensure syntax highlighting and **IntelliSense** work correctly.\n",
    "- If using R, ensure you have R installed on your system so that the R extension can detect it.\n",
    "\n",
    "Now, you're ready to start coding in both **Python** and **R** using VSCode! ðŸš€\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (PART) QUESTION & ANSWER (Q&A) {-}\n",
    "\n",
    "# How to Install Basic Libaries for Python and R \n",
    "\n",
    "## Explanation\n",
    "\n",
    "Before you can load datasets in Python and R, you need to install the necessary libraries. Here's how you can install the basic libraries required for this guide:\n",
    "\n",
    "## Python Code\n",
    "In your terminal, run the following command to install the necessary libraries for data manipulation, visualization, and machine learning:\n",
    "\n",
    "```bash\n",
    "pip install pandas matplotlib scikit-learn\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "In R, install the following packages to help with data manipulation and visualization:\n",
    "\n",
    "```r\n",
    "if (!require(tidyverse)) {install.packages('tidyverse')}\n",
    "library(tidyverse)\n",
    "\n",
    "if (!require(caret)) {install.packages('caret')}\n",
    "library(caret)\n",
    "```\n",
    "\n",
    "The **tidyverse** R package contains a collection of essential packages for data science, including:\n",
    "\n",
    "- **ggplot2** for data visualization  \n",
    "- **dplyr** for data manipulation  \n",
    "- **tidyr** for data tidying  \n",
    "- **readr** for reading and writing data files  \n",
    "- **purrr** for functional programming  \n",
    "- **tibble** for an improved data frame format  \n",
    "- **stringr** for string manipulation  \n",
    "- **forcats** for categorical variable handling  \n",
    "\n",
    "The **caret** package (short for *Classification and Regression Training*) is widely used for machine learning in R. It provides a unified interface for training and evaluating models, making it easier to apply machine learning techniques.\n",
    "\n",
    "These libraries and packages will ensure you have the tools you need to get started with data analysis and visualization in both languages.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Create a Project Directory in Python and R {#set-project-dir}\n",
    "\n",
    "## Explanation\n",
    "A well-organized project directory is key to efficient data science work. In this section, you will set up a project directory with separate folders for your datasets and scripts. Now that you have your environment set up, itâ€™s time to create your project directory. This will help keep your files organized as you progress through the guide.\n",
    "\n",
    "Create a new folder for your project, such as `beginner-data-science`. Inside this folder, create the following subfolders:\n",
    "\n",
    "- **data**: This folder will store your datasets.\n",
    "- **scripts**: Store Python or R scripts here.\n",
    "- **images**: Use this folder for images related to the project.\n",
    "\n",
    "**Example Structure:**\n",
    "\n",
    "```plaintext\n",
    "beginner-data-science/\n",
    "  â”œâ”€â”€ data/\n",
    "  â”œâ”€â”€ scripts/\n",
    "  â””â”€â”€ images/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Python Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory structure created at ./\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define project structure\n",
    "project_dir = './'\n",
    "data_dir = os.path.join(project_dir, 'data')\n",
    "scripts_dir = os.path.join(project_dir, 'scripts')\n",
    "images_dir = os.path.join(project_dir, 'images')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(scripts_dir, exist_ok=True)\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Project directory structure created at {project_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Define project structure\n",
    "project_dir <- \"./\"\n",
    "data_dir <- file.path(project_dir, \"data\")\n",
    "scripts_dir <- file.path(project_dir, \"scripts\")\n",
    "images_dir <- file.path(project_dir, \"images\")\n",
    "\n",
    "# Create directories\n",
    "dir.create(data_dir, showWarnings = FALSE)\n",
    "dir.create(scripts_dir, showWarnings = FALSE)\n",
    "dir.create(images_dir, showWarnings = FALSE)\n",
    "\n",
    "cat(\"Project directory structure created at\", project_dir, \"\\n\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Save a Dataset in Python and R\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Saving datasets is essential for storing processed data, sharing results, and reusing data in later analysis. In Python, we commonly use pandas to save datasets in CSV format. In R, readr::write_csv() and write.csv() are common functions for saving datasets. You will need to: \n",
    "\n",
    "1. Iris dataset is available from [this link](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data).\n",
    "2. Also comes with some python libraries such as sklearn.datasets in python and data() in R. \n",
    "\n",
    "Note! When working with datasets in both Python and R, itâ€™s essential to save them in a structured format. However, the column names in the Iris dataset differ slightly between Python and R:\n",
    "\n",
    "- Python (pandas version) uses:\n",
    "  - sepal length (cm), sepal width (cm), petal length (cm), petal width (cm), species\n",
    "- R (datasets::iris version) uses:\n",
    "  - Sepal.Length, Sepal.Width, Petal.Length, Petal.Width, Species\n",
    "\n",
    "To maintain consistency, we will save two separate versions:\n",
    "\n",
    "- iris-py.csv (from Python)\n",
    "- iris-r.csv (from R)\n",
    "\n",
    "This ensures that each dataset retains its original structure before standardization.\n",
    "\n",
    "## Python Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as 'data/iris_py.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the full iris dataset\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame\n",
    "\n",
    "# Add species names\n",
    "df[\"species\"] = df[\"target\"].map({0: \"setosa\", 1: \"versicolor\", 2: \"virginica\"})\n",
    "\n",
    "# Save the dataset as \"iris-py.csv\"\n",
    "df.to_csv(\"data/iris_py.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved as 'data/iris_py.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as 'data/iris_py.csv'\n"
     ]
    }
   ],
   "source": [
    "# Add species names\n",
    "df[\"species\"] = df[\"target\"].map({0: \"setosa\", 1: \"versicolor\", 2: \"virginica\"})\n",
    "\n",
    "# Save dataset with all columns\n",
    "df.to_csv(\"data/iris_py.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved as 'data/iris_py.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load necessary libraries\n",
    "library(readr)\n",
    "\n",
    "# Load the full iris dataset\n",
    "df <- datasets::iris\n",
    "\n",
    "# Save the dataset with species included using write_csv from readr\n",
    "write_csv(df, \"data/iris_r.csv\")\n",
    "\n",
    "# Confirmation message\n",
    "print(\"Dataset saved as 'data/iris_r.csv'\")\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Rename Column Names in Python and R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Since the column names differ between Python and R versions of the dataset, we will standardize them to ensure consistency. The renamed column names will be:\n",
    "\n",
    "- sepal_length\n",
    "- sepal_width\n",
    "- petal_length\n",
    "- petal_width\n",
    "- species\n",
    "\n",
    "This makes it easier to work with the dataset across different tools and languages.\n",
    "\n",
    "After Renaming, we will save the final dataset as iris.csv.\n",
    "\n",
    "## Python Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed dataset saved as 'data/iris.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/iris_py.csv\")\n",
    "\n",
    "# Rename columns\n",
    "df.rename(columns={'sepal length (cm)': 'sepal_length', \n",
    "                   'sepal width (cm)': 'sepal_width',\n",
    "                   'petal length (cm)': 'petal_length',\n",
    "                   'petal width (cm)': 'petal_width',\n",
    "                   'species': 'species'}, inplace=True)\n",
    "\n",
    "# Save the standardized dataset\n",
    "df.to_csv(\"data/iris.csv\", index=False)\n",
    "\n",
    "print(\"Renamed dataset saved as 'data/iris.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "library(readr)\n",
    "library(dplyr)\n",
    "\n",
    "# Load dataset\n",
    "df <- read_csv(\"data/iris_r.csv\")\n",
    "\n",
    "# Rename columns\n",
    "df <- df %>%\n",
    "  rename(sepal_length = Sepal.Length,\n",
    "         sepal_width = Sepal.Width,\n",
    "         petal_length = Petal.Length,\n",
    "         petal_width = Petal.Width,\n",
    "         species = Species)\n",
    "\n",
    "# Save the standardized dataset\n",
    "write_csv(df, \"data/iris.csv\")\n",
    "\n",
    "print(\"Renamed dataset saved as 'data/iris.csv'\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to load a dataset in Python and R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Loading a dataset is one of the first steps in any data analysis project. In this case, we'll load the Iris dataset, a popular dataset for beginner data science projects, in both Python and R. The dataset has been saved as `iris.csv` in your `data` folder.\n",
    "\n",
    "We will use **pandas** in Python and **readr** in R to load the dataset into a dataframe.\n",
    "\n",
    "- In Python we will use the `pandas` library, which is a powerful tool for data manipulation and analysis.\n",
    "- The `read_csv()` function in pandas will allow us to read the `iris.csv` file into a dataframe.\n",
    "\n",
    "- In R we will use the `readr` package, which provides modern and faster alternatives to base R functions.\n",
    "- The `read_csv()` function in `readr` is similar to pandas in Python and offers a streamlined approach for loading CSV files.\n",
    "\n",
    "\n",
    "## Python Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width  target species\n",
      "0           5.1          3.5           1.4          0.2       0  setosa\n",
      "1           4.9          3.0           1.4          0.2       0  setosa\n",
      "2           4.7          3.2           1.3          0.2       0  setosa\n",
      "3           4.6          3.1           1.5          0.2       0  setosa\n",
      "4           5.0          3.6           1.4          0.2       0  setosa\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "iris = pd.read_csv('data/iris.csv')\n",
    "\n",
    "# Show the first few rows\n",
    "print(iris.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load necessary library\n",
    "library(readr)\n",
    "\n",
    "# Load dataset from CSV file\n",
    "df <- read_csv(\"data/iris.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "head(df)\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Explore a Dataset in Python and R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "After loading a dataset, it is important to explore its structure, summary statistics, and key properties before performing any analysis. This helps in understanding the data and identifying potential issues such as missing values or outliers.\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "- View the structure of the dataset.\n",
    "- Get summary statistics.\n",
    "- Check for missing values.\n",
    "\n",
    "## Python Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   target        150 non-null    int64  \n",
      " 5   species       150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "       sepal_length  sepal_width  petal_length  petal_width      target\n",
      "count    150.000000   150.000000    150.000000   150.000000  150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333    1.000000\n",
      "std        0.828066     0.435866      1.765298     0.762238    0.819232\n",
      "min        4.300000     2.000000      1.000000     0.100000    0.000000\n",
      "25%        5.100000     2.800000      1.600000     0.300000    0.000000\n",
      "50%        5.800000     3.000000      4.350000     1.300000    1.000000\n",
      "75%        6.400000     3.300000      5.100000     1.800000    2.000000\n",
      "max        7.900000     4.400000      6.900000     2.500000    2.000000\n",
      "\n",
      "Missing Values:\n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "target          0\n",
      "species         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "iris = pd.read_csv('data/iris.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print(iris.info())\n",
    "\n",
    "# Show summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(iris.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(iris.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load necessary library\n",
    "library(readr)\n",
    "library(dplyr)\n",
    "\n",
    "# Load the dataset\n",
    "df <- read_csv(\"data/iris.csv\")\n",
    "\n",
    "# Display the structure of the dataset\n",
    "cat(\"Dataset Structure:\\n\")\n",
    "str(df)\n",
    "\n",
    "# Show summary statistics\n",
    "cat(\"\\nSummary Statistics:\\n\")\n",
    "summary(df)\n",
    "\n",
    "# Check for missing values\n",
    "cat(\"\\nMissing Values:\\n\")\n",
    "colSums(is.na(df))\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Handle Missing Data in Python and R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Handling missing data is one of the most important steps in data cleaning. In this section, weâ€™ll explore how to handle missing values in a dataset. There are several strategies for handling missing data, such as:\n",
    "\n",
    "- **Removing missing values**\n",
    "- **Imputing missing values** (filling them with a specific value or a calculated statistic)\n",
    "\n",
    "In this guide, we will focus on removing missing values, though you can also explore imputation depending on your data and goals.\n",
    "\n",
    "## Python Code\n",
    "\n",
    "In Python, we can use **pandas** to detect and handle missing data. The `isna()` and `dropna()` functions are commonly used for this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "target          0\n",
      "species         0\n",
      "dtype: int64\n",
      "   sepal_length  sepal_width  petal_length  petal_width  target species\n",
      "0           5.1          3.5           1.4          0.2       0  setosa\n",
      "1           4.9          3.0           1.4          0.2       0  setosa\n",
      "2           4.7          3.2           1.3          0.2       0  setosa\n",
      "3           4.6          3.1           1.5          0.2       0  setosa\n",
      "4           5.0          3.6           1.4          0.2       0  setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/iris.csv\")\n",
    "df\n",
    "# Check for missing values\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Remove rows with missing data\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Check the cleaned data\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "In R, we can use the is.na() function to detect missing values, and the na.omit() function to remove them.\n",
    "\n",
    "```{r}\n",
    "library(dplyr)\n",
    "library(readr)\n",
    "\n",
    "# Load dataset\n",
    "df <- read_csv(\"data/iris.csv\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values <- colSums(is.na(df))\n",
    "print(missing_values)\n",
    "\n",
    "# Remove rows with missing data\n",
    "df_cleaned <- na.omit(df)\n",
    "\n",
    "# Check the cleaned data\n",
    "head(df_cleaned)\n",
    "```\n",
    "\n",
    "Handling missing data properly ensures that your analysis is accurate and that missing values do not introduce bias into your model or analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Filter Data in Python and R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Filtering data is a common task in data science. It allows you to select specific rows based on conditions or criteria, helping you focus on the subset of data that is most relevant to your analysis.\n",
    "\n",
    "In this section, we will learn how to filter data using conditions in both Python and R. We'll demonstrate filtering rows based on specific column values.\n",
    "\n",
    "## Python Code\n",
    "\n",
    "In Python, we use **pandas** to filter data. The `loc[]` method is useful for selecting rows based on specific conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width  target species\n",
      "0           5.1          3.5           1.4          0.2       0  setosa\n",
      "1           4.9          3.0           1.4          0.2       0  setosa\n",
      "2           4.7          3.2           1.3          0.2       0  setosa\n",
      "3           4.6          3.1           1.5          0.2       0  setosa\n",
      "4           5.0          3.6           1.4          0.2       0  setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/iris.csv\")\n",
    "\n",
    "# Filter rows where species is 'setosa'\n",
    "setosa_df = df[df['species'] == 'setosa']\n",
    "\n",
    "# Show the first few rows of the filtered data\n",
    "print(setosa_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "In R, we can use the dplyr package to filter rows based on specific conditions. The filter() function is used for this purpose.\n",
    "\n",
    "\n",
    "```{r}\n",
    "library(dplyr)\n",
    "library(readr)\n",
    "\n",
    "# Load dataset\n",
    "df <- read_csv(\"data/iris.csv\")\n",
    "\n",
    "# Filter rows where species is 'setosa'\n",
    "setosa_df <- df %>% filter(species == 'setosa')\n",
    "\n",
    "# Show the first few rows of the filtered data\n",
    "head(setosa_df)\n",
    "```\n",
    "\n",
    "Filtering data allows you to narrow down your dataset and focus on specific insights or subsets of interest. In real-world projects, filtering is often one of the first steps in analyzing a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Group Data in Python and R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Grouping data is a common task when summarizing and analyzing datasets. In this section, weâ€™ll group the Iris dataset by the Species column and calculate summary statistics (e.g., mean) for each group.\n",
    "\n",
    "In Python, we use **pandas** for this task, while in R we use **dplyr**. Letâ€™s explore how to group the data by species and calculate the mean of each numeric column.\n",
    "\n",
    "## Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sepal_length  sepal_width  petal_length  petal_width  target\n",
      "species                                                                 \n",
      "setosa             5.006        3.428         1.462        0.246     0.0\n",
      "versicolor         5.936        2.770         4.260        1.326     1.0\n",
      "virginica          6.588        2.974         5.552        2.026     2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/iris.csv\")\n",
    "\n",
    "# Group by 'Species' and calculate the mean for each group\n",
    "grouped_df = df.groupby('species').mean()\n",
    "\n",
    "# Display the grouped data\n",
    "print(grouped_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "library(dplyr)\n",
    "library(readr)\n",
    "\n",
    "# Load dataset\n",
    "df <- read_csv(\"data/iris.csv\")\n",
    "\n",
    "# Group by 'species' and calculate the mean for each group\n",
    "grouped_df <- df %>%\n",
    "  group_by(species) %>%\n",
    "  summarise(across(where(is.numeric), mean))\n",
    "\n",
    "# Display the grouped data\n",
    "print(grouped_df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Aggregate Data in Python and R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Aggregation helps summarize datasets by computing statistics such as mean, median, count, or sum for different groups. This is useful when analyzing patterns within the dataset.\n",
    "\n",
    "For example, in the iris dataset, we can find the average sepal width per species to compare flower characteristics.\n",
    "\n",
    "## Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      species  sepal_width\n",
      "0      setosa        3.428\n",
      "1  versicolor        2.770\n",
      "2   virginica        2.974\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/iris.csv\")\n",
    "\n",
    "# Aggregate: Calculate mean sepal width per species\n",
    "agg_df = df.groupby(\"species\")[\"sepal_width\"].mean().reset_index()\n",
    "\n",
    "# Save the aggregated data\n",
    "agg_df.to_csv(\"data/iris_aggregated_py.csv\", index=False)\n",
    "\n",
    "# Display the result\n",
    "print(agg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load necessary libraries\n",
    "library(readr)\n",
    "library(dplyr)\n",
    "\n",
    "# Load the dataset\n",
    "df <- read_csv(\"data/iris.csv\")\n",
    "\n",
    "# Aggregate: Calculate mean sepal width per species\n",
    "agg_df <- df %>%\n",
    "  group_by(species) %>%\n",
    "  summarise(mean_sepal_width = mean(sepal_width, na.rm = TRUE))\n",
    "\n",
    "# Save the aggregated data\n",
    "write_csv(agg_df, \"data/iris_aggregated_r.csv\")\n",
    "\n",
    "# Display the result\n",
    "print(agg_df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Split a Dataset in Python and R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Splitting a dataset into multiple parts is useful when you want to work with subsets of data. In this case, we will split the iris dataset into two parts:\n",
    "x\n",
    "- **iris_part1.csv**: Contains columns sepal_length, sepal_width, and species.\n",
    "- **iris_part2.csv**: Contains columns petal_length, petal_width, and species.\n",
    "\n",
    "These parts will later be merged based on the **species** column.\n",
    "\n",
    "## Python Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts saved as iris_part1.csv and iris_part2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the iris dataset\n",
    "df = pd.read_csv(\"data/iris.csv\")\n",
    "\n",
    "# Split into two parts\n",
    "part1 = df[['sepal_length', 'sepal_width', 'species']]\n",
    "part2 = df[['petal_length', 'petal_width', 'species']]\n",
    "\n",
    "# Save the parts as separate CSV files\n",
    "part1.to_csv(\"data/iris_part1.csv\", index=False)\n",
    "part2.to_csv(\"data/iris_part2.csv\", index=False)\n",
    "\n",
    "# Display a message to confirm\n",
    "print(\"Parts saved as iris_part1.csv and iris_part2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load necessary libraries\n",
    "library(readr)\n",
    "\n",
    "# Load the iris dataset\n",
    "df <- read_csv(\"data/iris.csv\")\n",
    "\n",
    "# Split into two parts\n",
    "part1 <- df[, c(\"sepal_length\", \"sepal_width\", \"species\")]\n",
    "part2 <- df[, c(\"petal_length\", \"petal_width\", \"species\")]\n",
    "\n",
    "# Save the parts as separate CSV files\n",
    "write_csv(part1, \"data/iris_part1.csv\")\n",
    "write_csv(part2, \"data/iris_part2.csv\")\n",
    "\n",
    "# Display a message to confirm\n",
    "cat(\"Parts saved as iris_part1.csv and iris_part2.csv\\n\")\n",
    "```\n",
    "\n",
    "\n",
    "Now that we have created the two parts, we can proceed to merge them using the steps outlined previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Merge Datasets in Python and R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Merging datasets is a common task when working with multiple data sources. In the iris dataset, we may want to combine different subsets of data based on a common column, such as the species.\n",
    "\n",
    "In this example, we assume there are two datasets:\n",
    "\n",
    "- iris_part1.csv (contains sepal_length, sepal_width, and species)\n",
    "- iris_part2.csv (contains petal_length, petal_width, and species)\n",
    "\n",
    "We will merge them on the species column.\n",
    "\n",
    "## Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width species  petal_length  petal_width\n",
      "0           5.1          3.5  setosa           1.4          0.2\n",
      "1           5.1          3.5  setosa           1.4          0.2\n",
      "2           5.1          3.5  setosa           1.3          0.2\n",
      "3           5.1          3.5  setosa           1.5          0.2\n",
      "4           5.1          3.5  setosa           1.4          0.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two parts of the iris dataset (with renamed columns)\n",
    "part1 = pd.read_csv(\"data/iris_part1.csv\")\n",
    "part2 = pd.read_csv(\"data/iris_part2.csv\")\n",
    "\n",
    "# Merge the datasets based on the 'species' column\n",
    "merged_df = pd.merge(part1, part2, on='species')\n",
    "\n",
    "# Save the merged dataset as a new CSV file\n",
    "merged_df.to_csv(\"data/iris_merged.csv\", index=False)\n",
    "\n",
    "# Display the first few rows of the merged dataset\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load necessary library\n",
    "library(readr)\n",
    "\n",
    "# Load the two parts of the iris dataset (with renamed columns)\n",
    "part1 <- read_csv(\"data/iris_part1.csv\")\n",
    "part2 <- read_csv(\"data/iris_part2.csv\")\n",
    "\n",
    "# Merge the datasets based on the 'species' column\n",
    "merged_df <- merge(part1, part2, by = \"species\")\n",
    "\n",
    "# Save the merged dataset as a new CSV file\n",
    "write_csv(merged_df, \"data/iris_merged.csv\")\n",
    "\n",
    "# Display the first few rows of the merged dataset\n",
    "head(merged_df)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
